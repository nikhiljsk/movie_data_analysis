{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytesseract'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ba935ae773e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpytesseract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytesseract'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "class ImageProcessing:\n",
    "    \n",
    "    def image_process(self):\n",
    "        \n",
    "        path='c:\\data_analysis'\n",
    "        # load the image \n",
    "        img_path=input(\"Enter the complete path of the image file\")\n",
    "        img=Image.open(img_path)\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        print(\"Hold until we process your Image.....\")\n",
    "        #convert the image type into numpy array for processing\n",
    "        image_data = np.asarray(img)\n",
    "        #denoising the image\n",
    "        dst = cv2.fastNlMeansDenoisingColored(image_data,None,10,10,7,21)\n",
    "        #saving the denoised image\n",
    "        cv2.imwrite(r'c:\\data_analysis\\deionise.png', dst)\n",
    "        #to convert tesseract_cmd file to tesseract.exe\n",
    "        pytesseract.pytesseract.tesseract_cmd = \"C:/Program Files/Tesseract 4.0.0/tesseract.exe\"\n",
    "        pytesseract.pytesseract.tesseract_cmd = 'C:/Program Files/Tesseract-OCR/tesseract.exe'\n",
    "        #converting the image into grayscale\n",
    "        gray = cv2.cvtColor(image_data, cv2.COLOR_BGR2GRAY)\n",
    "        #saving the grayscale image\n",
    "        cv2.imwrite(r'c:\\data_analysis\\enhancedGrayscaleLineCapture.png', gray)\n",
    "        #to increase the threshold of the image\n",
    "        th1 = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "                                    cv2.THRESH_BINARY,11,2)\n",
    "        ret2,th2 = cv2.threshold(gray,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "        ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        blue, green, red = cv2.split(image_data)\n",
    "        blue_edges = cv2.Canny(blue, 100, 10)       \n",
    "        green_edges = cv2.Canny(green, 100, 10)\n",
    "        red_edges = cv2.Canny(red, 100, 10)\n",
    "        edges = blue_edges | green_edges | red_edges\n",
    "        #saving enhanced gray scale threshold,grayscaled images\n",
    "        cv2.imwrite(r'c:\\data_analysis\\enhancedGrayscaleThresholdLineCapture.png', th2)\n",
    "        cv2.imwrite(r'c:\\data_analysis\\bluegreenred.png', edges)\n",
    "        img2=Image.open(r'c:\\data_analysis\\enhancedGrayscaleThresholdLineCapture.png')\n",
    "        img1=Image.open(r'c:\\data_analysis\\bluegreenred.png')\n",
    "        images=Image.open(r'c:\\data_analysis\\deionise.png')\n",
    "        #extract text from denoised image\n",
    "        result=pytesseract.image_to_string(images,lang='eng')\n",
    "        output_temp=result.split()\n",
    "        for i in range(len(output_temp)):\n",
    "            output_temp[i]=output_temp[i].lower()\n",
    "        output_vectors=[]\n",
    "        \"\"\"for i in range(len(output_temp)):\n",
    "            output_vectors.append(len(output_temp[i]))\n",
    "        x=max(output_vectors)\n",
    "        for k in range(len(output_vectors)):\n",
    "            if(x==output_vectors[k]):\n",
    "                x=k\n",
    "                break\n",
    "        output=output_temp[x]\"\"\"\n",
    "        return output_temp    \n",
    "\n",
    "\n",
    "class NLP:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.output_vectors=[]\n",
    "        self.input_text_vectors=[]\n",
    "        self.constraints_vectors=[]\n",
    "        self.keywords_vectors=[]\n",
    "        self.output=[]\n",
    "        self.num_words=1000\n",
    "        self.number_of_constraints=0\n",
    "        ck = pd.read_csv(\"./const_key.csv\")  #ck.iloc[:, 0]\n",
    "        self.keywords=ck.iloc[0:3, 1].tolist()\n",
    "        self.constraints = (ck.iloc[:, 0]).tolist()\n",
    "        self.input_text = \"\"\n",
    "        self.temp =[]\n",
    "        self.key_count = 0\n",
    "        \n",
    "    def input_query(self):\n",
    "        self.input_text=input(\"Enter Your Query:\\n\")\n",
    "        \n",
    "    def processing(self):\n",
    "        self.temp=(self.input_text).split(\" \")\n",
    "        l1=self.temp+self.constraints+self.keywords\n",
    "        l = [l1]\n",
    "        tokenizer=Tokenizer(num_words=self.num_words)\n",
    "        tokenizer.fit_on_texts(l)\n",
    "        token_outputs=tokenizer.word_index\n",
    "        for i in range(len(self.temp)):\n",
    "            self.input_text_vectors.append(token_outputs[self.temp[i]])\n",
    "        for j in range(len(self.constraints)):\n",
    "            self.constraints_vectors.append(token_outputs[self.constraints[j]])\n",
    "        for k in range(len(self.keywords)):\n",
    "            self.keywords_vectors.append(token_outputs[self.keywords[k]])\n",
    "        for m in range(len(self.input_text_vectors)):\n",
    "            for n in range(len(self.constraints_vectors)):\n",
    "                if(self.input_text_vectors[m]==self.constraints_vectors[n]):\n",
    "                    self.output_vectors.append(self.input_text_vectors[m])\n",
    "                    self.number_of_constraints+=1\n",
    "        for o in range(len(self.input_text_vectors)):\n",
    "            for p in range(len(self.keywords_vectors)):\n",
    "                if(self.input_text_vectors[o]==self.keywords_vectors[p]):#must handle array index out of bound error and print query incomplete\n",
    "                    try:\n",
    "                        self.key_count += 1\n",
    "                        self.output_vectors.append(self.input_text_vectors[o+1])\n",
    "                    except IndexError as e:\n",
    "                        print(\"Query does not contain enough parameters.\")\n",
    "                        return self.processing()\n",
    "        self.output.append(self.number_of_constraints)\n",
    "        for q in range(len(self.output_vectors)):\n",
    "            for value,vectors in token_outputs.items():\n",
    "                if (self.output_vectors[q]==vectors):\n",
    "                    self.output.append(value)\n",
    "        if 'predict' in self.output:\n",
    "            return self.output\n",
    "        if self.number_of_constraints <= self.key_count:\n",
    "            return self.output\n",
    "        else:\n",
    "            print(\"Not enough keywords\")\n",
    "            self.input_query()\n",
    "\n",
    "class Visualize:\n",
    "    def __init__(self):\n",
    "        self.df1 = pd.read_csv('./movie_name_char_mentions_centrality.csv')\n",
    "        self.df2 = pd.read_csv('./movie_emotion_year.csv')\n",
    "        self.df3 = pd.read_csv('./movie_singer_count.csv')\n",
    "        self.df4 = pd.read_csv('./movie_plot.csv')\n",
    "        self.df5 = pd.read_csv('./movie_all.csv')\n",
    "        \n",
    "    def lead_role(self, q):\n",
    "        col = self.df1[self.df1['movie']==q]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", q, \" is not found in the database. Try again with another value.\", sep=\"\")\n",
    "            return\n",
    "        ser = col['name']\n",
    "        result = 'actor' in ser.values\n",
    "        if(result):\n",
    "            print(\"The lead role is 'actor'\")\n",
    "            print(\"The type of role played is: \", col[col['name'].values=='actor']['character'])\n",
    "            \n",
    "        else:\n",
    "            col = col.sort_values(by=['count'], ascending=False)\n",
    "            ser = col['name']\n",
    "            nam = ser.values[0]\n",
    "            ind = ser[ser==nam].index[0]\n",
    "            print(\"The lead role is:\", nam)\n",
    "            print(\"The type of role played is: \", self.df1[self.df1['index']==ind]['character'].values[0])\n",
    "            \n",
    "    def characters(self, q):\n",
    "        col = self.df1[self.df1['movie']==q]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", q, \" is not found in the database. Try again with another value.\", sep=\"\")\n",
    "            return\n",
    "        ser = col['name']\n",
    "        print(\"The characters in the movies\", q, \"include:\")\n",
    "        print(col[['name', 'character']])\n",
    "        \n",
    "    def character(self, q, m):\n",
    "        col = self.df1[self.df1['movie']==m]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", m, \" is not found in the database. Try again with another value.\", sep=\"\")\n",
    "            return\n",
    "        ser = col['name']\n",
    "        nam = \"NULL\"\n",
    "        try:\n",
    "            nam = ser[ser==q].values[0]\n",
    "        except IndexError as e:\n",
    "            print(\"The character \", q, \" is not found in the database.Try again with another value.\", sep=\"\")\n",
    "            return\n",
    "        ind = ser[ser==nam].index[0]\n",
    "        print(\"The role is:\", nam)\n",
    "        print(\"The type of role played is: \", self.df1[self.df1['index']==ind]['character'].values[0])\n",
    "        \n",
    "    def plot(self, m):\n",
    "        pd.set_option('display.max_colwidth', -1)\n",
    "        col = self.df4[self.df4['movie']==m]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", m, \" is not found in the database. Try again with another value.\", sep=\"\")\n",
    "            return\n",
    "        print(\"The plot of the film goes like: \")\n",
    "        print(col['plot'])\n",
    "        \n",
    "    def appearances(self, c, m):\n",
    "        col = self.df1[self.df1['movie'] == m]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", m, \" is not found in the database. Try again with another value.\", sep=\"\")\n",
    "            return\n",
    "        ser = col['name']\n",
    "        try:\n",
    "            nam = ser[ser==c].values[0]\n",
    "        except IndexError as e:\n",
    "            print(\"The character \", c, \" is not found in the database.Try again with another value.\", sep=\"\")\n",
    "            return\n",
    "        ind = ser[ser==nam].index[0]\n",
    "        print(\"The role is:\", nam)\n",
    "        print(\"The number of appearances are: \", self.df1[self.df1['index']==ind]['count'].values[0])\n",
    "        print(\"The average centrality is: \", self.df1[self.df1['index']==ind]['average centrality'].values[0])\n",
    "        print(\"The total centrality is: \", self.df1[self.df1['index']==ind]['total centrality'].values[0])\n",
    "       \n",
    "        \n",
    "    def year(self, m):\n",
    "        col = self.df2[self.df2['movie'] == m]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", m, \" is not found in the database. Try again with another value.\", sep=\"\")\n",
    "            return\n",
    "        print(\"The movie\", m, \"released in the year\",col['year'].values[0])\n",
    "        \n",
    "    def songs(self, m):\n",
    "        col = self.df3[self.df3['movie'] == m]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", m, \" is not found in the database. Try again with another value.\", sep=\"\")\n",
    "            return\n",
    "        singers = col['singer_name'].values.tolist()\n",
    "        print(\"The movie\", m, \"has\", col['song_count'].sum(), \"songs.\\n\")\n",
    "        print(\"And the singers are:\\n\", \"\\n \".join(singers))\n",
    "        \n",
    "    def average_emotion(self, m, n):\n",
    "        col = self.df2[self.df2['movie']==m]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", m, \" is not found in the database. Try again with another value.\", sep=\"\")\n",
    "            return\n",
    "        se = col['emotion'].value_counts()\n",
    "        if(n==0):\n",
    "            fig, ax = plt.subplots(figsize=(12, 6), subplot_kw=dict(aspect=\"equal\"))\n",
    "            recipe = se.index\n",
    "            data = se.values\n",
    "            wedges, texts = ax.pie(data, wedgeprops=dict(width=0.5), startangle=-40)\n",
    "            bbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.72)\n",
    "            kw = dict(xycoords='data', textcoords='data', arrowprops=dict(arrowstyle=\"-\"),\n",
    "                      bbox=bbox_props, zorder=0, va=\"center\")\n",
    "            for i, p in enumerate(wedges):\n",
    "                ang = (p.theta2 - p.theta1)/2. + p.theta1\n",
    "                y = np.sin(np.deg2rad(ang))\n",
    "                x = np.cos(np.deg2rad(ang))\n",
    "                horizontalalignment = {-1: \"right\", 1: \"left\"}[int(np.sign(x))]\n",
    "                connectionstyle = \"angle,angleA=0,angleB={}\".format(ang)\n",
    "                kw[\"arrowprops\"].update({\"connectionstyle\": connectionstyle})\n",
    "                ax.annotate(recipe[i], xy=(x, y), xytext=(1.35*np.sign(x), 1.4*y),horizontalalignment=horizontalalignment, **kw)\n",
    "            ax.set_title(\"Average Emotion\")\n",
    "        \n",
    "            plt.show()\n",
    "        \n",
    "        maxi = max(se.values)\n",
    "        mini = min(se.values)\n",
    "        max_per = (maxi/sum(se.values))*100\n",
    "        min_per = (mini/sum(se.values))*100\n",
    "        if(n==2):\n",
    "            print('\\nThe most expressed emotion in the film is \"',se[se == maxi].index[0],'\"',\" and constitutes to \", max_per,\"%\",sep=\"\")\n",
    "        if(n==1):\n",
    "            print('\\nThe least expressed emotion in the film is \"',se[se == mini].index[0],'\"',\" and constitutes to \", min_per,\"%\", sep=\"\")\n",
    "       \n",
    "        # creating word cloud\n",
    "        if(n==0):\n",
    "            self.create_wordcloud(col)\n",
    "        \n",
    "        if(n==0):\n",
    "            # genre of the film\n",
    "            self.genre(m)\n",
    "        \n",
    "    def create_wordcloud(self, q):\n",
    "        from wordcloud import WordCloud, STOPWORDS \n",
    "        print(\"\\n\\nThe wordcloud created for the emotions of the data in the film:\\n\")\n",
    "        comment_words = ' '\n",
    "        stopwords = set(STOPWORDS) \n",
    "\n",
    "        for val in q: \n",
    "            val = str(val) \n",
    "            tokens = val.split()  \n",
    "            for i in range(len(tokens)): \n",
    "                tokens[i] = tokens[i].lower() \n",
    "\n",
    "            for words in tokens: \n",
    "                comment_words = comment_words + words + ' '\n",
    "\n",
    "\n",
    "        wordcloud = WordCloud(width = 800, height = 800, \n",
    "                        background_color ='white', \n",
    "                        stopwords = stopwords, \n",
    "                        min_font_size = 10).generate(' '.join(q['emotion'])) \n",
    "\n",
    "        plt.figure(figsize = (4, 4), facecolor = None) \n",
    "        plt.imshow(wordcloud) \n",
    "        plt.axis(\"off\") \n",
    "        plt.tight_layout(pad = 0) \n",
    "        plt.show()\n",
    "        print(\"Note: The the size of the word increases with higher expressed emotion.\")\n",
    "        \n",
    "    def genre(self, m):\n",
    "        col = self.df2[self.df2['movie']==m]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", m, \" is not found in the database. Try again with another value.\", sep=\"\")\n",
    "            return\n",
    "        se = col['emotion'].value_counts()\n",
    "        gen = se[se == max(se.values)].index[0]\n",
    "        \n",
    "        #fuzzying the output\n",
    "        \n",
    "        if(gen==\"happy\"):\n",
    "            genre = \"Family-Entertainer\"\n",
    "        elif(gen == \"neutral\"):\n",
    "            genre = \"Drama\"\n",
    "        elif(gen == \"sad\"):\n",
    "            genre = \"Melo-Drama\"\n",
    "        elif(gen == \"angry\"):\n",
    "            genre = \"Action\"\n",
    "        elif(gen == \"fear\"):\n",
    "            genre = \"Horror\"\n",
    "        elif(gen==\"suprise\"):\n",
    "            genre = \"Suspence Thriller\"\n",
    "        elif(gen==\"disgust\"):\n",
    "            genre = \"Crime-Thriller\"\n",
    "        print(\"GENRE:\")\n",
    "        print(\"The movie \", m, \" is a \", genre, \" genre film.\", sep=\"\")\n",
    "        \n",
    "    def length_of_movie(self, m):\n",
    "        col = self.df1[self.df1['movie']==m]\n",
    "        if(col.empty):\n",
    "            print(\"The movie \", m, \" is not found in the database. Try again with another value.\", sep=\"\")\n",
    "            return\n",
    "        se1 = col['mentions'].sum()\n",
    "        se2 = col['count'].sum()\n",
    "        se3 = col['total centrality'].sum()\n",
    "        se4 = col['average centrality'].sum()\n",
    "        result = se1 + (se3/se2) + se4                               # creating an estimation variable\n",
    "        est_time = 150\n",
    "        est_result = 70\n",
    "        if(35<result<est_result):                                    # fuzzyfying the result into time or length of movie\n",
    "            length = est_time\n",
    "        elif(30<result<est_result/2):\n",
    "            length = est_time-20\n",
    "        elif(70<result<est_result*2):\n",
    "            length = est_time+20\n",
    "        elif(140<result<est_result*4):\n",
    "            length = est_time+10\n",
    "        else:\n",
    "            length = est_time - 10\n",
    "        print(\"The predicted length of movie \", m, \" on the basis of Centrality and Mentions is about \", np.round((length/60), 2),sep=\"\")\n",
    "\n",
    "    def trends(self, bol):\n",
    "        df = {}\n",
    "        for i in range(10):\n",
    "            df[i] = self.df2[self.df2['year']==2008+i]['emotion'].value_counts().to_frame()\n",
    "            df[i].columns = [2008+i]\n",
    "        df_area = pd.concat([df[0], df[1], df[2], df[3], df[4], df[5], df[6], df[7],df[8], df[9]], axis=1)\n",
    "        if(bol):\n",
    "            print(df_area)\n",
    "            df_area.transpose().plot.area()\n",
    "            plt.xlabel(\"Year\")\n",
    "            plt.ylabel(\"Range\")\n",
    "            plt.show()\n",
    "        else:\n",
    "            return df_area\n",
    "        \n",
    "    def predict(self):\n",
    "        df_area = self.trends(False)\n",
    "        print(df_area)\n",
    "        # Data-Preprocessing\n",
    "        z = pd.read_csv('./trend_emotion.csv')\n",
    "        X = z.iloc[:, :-1]\n",
    "        y = z.iloc[:, -1]\n",
    "        # Spliting Data \n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        # Linear Regression\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        lm = LinearRegression()\n",
    "        lm.fit(X_train, y_train)\n",
    "        predictions_lin = lm.predict(X_test)\n",
    "       \n",
    "        # Calculating the Result in terms of errors\n",
    "        from sklearn import metrics\n",
    "        result = list()\n",
    "        result.append(metrics.mean_squared_error(y_test, predictions_lin))\n",
    "        result = np.array(result)\n",
    "        new = list()\n",
    "        emotions = ['angry', 'disgust', 'fear', 'happy', 'neurtal', 'sad', 'suprise']\n",
    "        print(\"\\n\")\n",
    "        for i in range(7):\n",
    "            print(\"Enter value of\",emotions[i],\":\", end=\"\")\n",
    "            new.append(int(input()))\n",
    "        result = lm.predict([new])\n",
    "        print(\"\\nThe predicted year according the values given is \",result[0])\n",
    "        \n",
    "    def image_movie(self, arr):\n",
    "        for i in range(len(arr)):\n",
    "            print(arr[i])\n",
    "            if arr[i] in self.df5.iloc[:, -1].values:\n",
    "                m = arr[i]\n",
    "                self.lead_role(m)\n",
    "                self.characters(m)\n",
    "                self.plot(m)\n",
    "                self.year(m)\n",
    "                self.songs(m)\n",
    "                self.average_emotion(m, 0)\n",
    "                self.length_of_movie(m)\n",
    "                return\n",
    "        print(\"Could not find the movie in the dataset\")\n",
    "        \n",
    "\n",
    "# Driver Code\n",
    "\n",
    "# input using NLP\n",
    "ext = 0         # checking for exit condition  \n",
    "while ext!=1:\n",
    "    obj = Visualize()\n",
    "    print(\"\\n\")\n",
    "    choice = int(input(\"Enter your choice:\\n1.Image Input\\n2.Text Input\\n3.Exit\\n\"))\n",
    "    if choice == 1:\n",
    "        ob = ImageProcessing()\n",
    "        tensor = ob.image_process()\n",
    "        obj.image_movie(tensor)\n",
    "        continue\n",
    "    elif choice == 2:\n",
    "        print(\"Queries can be framed using the following to get optimum results:\")\n",
    "        print(\"1.characters\\n2.plot\\n3.genre\\n4.attitude\\n5.appearances\\n6.year\\n7.songs\\n8.length\\n9.variation\\n10.predict\\n11.emotion\\n12.role\\n13.exit\\n14.movie\\n15.emotions\\n16.character\\n\")\n",
    "        ob = NLP()\n",
    "        ob.input_query()\n",
    "        tensor = ob.processing()\n",
    "    elif choice == 3:\n",
    "        print(\"Interupt Process\")\n",
    "        break;\n",
    "    else:\n",
    "        print(\"Invalid Input\")\n",
    "        continue\n",
    "    # Visualizing the queries\n",
    "    \n",
    "    count = tensor[0]\n",
    "    for i in range(1, tensor[0]+1):\n",
    "        \n",
    "        if tensor[i]==\"role\":\n",
    "            obj.lead_role(tensor[i + count])\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        elif tensor[i]==\"characters\":\n",
    "            obj.characters(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        elif tensor[i]==\"attitude\":\n",
    "            obj.character(tensor[i+count], tensor[i+count+1])\n",
    "            count += 1\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        elif tensor[i]==\"plot\":\n",
    "            obj.plot(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        elif tensor[i]==\"appearances\":\n",
    "            obj.appearances(tensor[i+count], tensor[i+count+1])\n",
    "            count += 1\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        elif tensor[i]==\"year\":\n",
    "            obj.year(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        elif tensor[i]==\"songs\":\n",
    "            obj.songs(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        elif tensor[i]==\"emotion\":\n",
    "            try:\n",
    "                if (\"average\" in ob.temp):\n",
    "                    obj.average_emotion(tensor[i+count], 0)\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "                elif (\"minor\" in ob.temp):\n",
    "                    obj.average_emotion(tensor[i+count], 1)\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "                elif (\"major\" in ob.temp):\n",
    "                    obj.average_emotion(tensor[i+count], 2)\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "                elif(\"predict\" in ob.temp):\n",
    "                    obj.predict()\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "            except IndexError as e:\n",
    "                print(\"Not enough parameters\")\n",
    "                break\n",
    "        \n",
    "        elif tensor[i]==\"genre\":\n",
    "            obj.genre(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        elif tensor[i]==\"length\":\n",
    "            obj.length_of_movie(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "\n",
    "        elif tensor[i]==\"variation\":\n",
    "            obj.trends(True)\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            \n",
    "        elif tensor[i]==\"exit\":\n",
    "            print(\"Process Interupt\")\n",
    "            ext = 1\n",
    "        else:\n",
    "            print(\"Query does not contain enough parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input_text_query(input_string, ob):\n",
    "    ob = NLP()\n",
    "    ob.input_query(input_string)\n",
    "    tensor = ob.processing()\n",
    "    output_string = generic_process(tensor)\n",
    "    return output_string\n",
    "\n",
    "def process_input_image_query(path):\n",
    "    ob = ImageProcessing()\n",
    "    tensor = ob.image_process()\n",
    "    output_list = obj.image_movie(tensor)          # Contains string, image saved path\n",
    "    return output_list\n",
    "    \n",
    "def generic_process(tensor, obj):\n",
    "    count = tensor[0]\n",
    "    for i in range(1, tensor[0]+1):\n",
    "        \n",
    "        if tensor[i]==\"role\":\n",
    "            obj.lead_role(tensor[i + count])\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        elif tensor[i]==\"characters\":\n",
    "            obj.characters(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        elif tensor[i]==\"attitude\":\n",
    "            obj.character(tensor[i+count], tensor[i+count+1])\n",
    "            count += 1\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        elif tensor[i]==\"plot\":\n",
    "            obj.plot(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        elif tensor[i]==\"appearances\":\n",
    "            obj.appearances(tensor[i+count], tensor[i+count+1])\n",
    "            count += 1\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        elif tensor[i]==\"year\":\n",
    "            obj.year(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        elif tensor[i]==\"songs\":\n",
    "            obj.songs(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        elif tensor[i]==\"emotion\":\n",
    "            try:\n",
    "                if (\"average\" in ob.temp):\n",
    "                    obj.average_emotion(tensor[i+count], 0)\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "                elif (\"minor\" in ob.temp):\n",
    "                    obj.average_emotion(tensor[i+count], 1)\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "                elif (\"major\" in ob.temp):\n",
    "                    obj.average_emotion(tensor[i+count], 2)\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "                elif(\"predict\" in ob.temp):\n",
    "                    obj.predict()\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "            except IndexError as e:\n",
    "                print(\"Not enough parameters\")\n",
    "                break\n",
    "        \n",
    "        elif tensor[i]==\"genre\":\n",
    "            obj.genre(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        elif tensor[i]==\"length\":\n",
    "            obj.length_of_movie(tensor[i+count])\n",
    "            print(\"\\n\")\n",
    "\n",
    "        elif tensor[i]==\"variation\":\n",
    "            obj.trends(True)\n",
    "            print(\"\\n\")\n",
    "\n",
    "        else:\n",
    "            print(\"Query does not contain enough parameters.\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
